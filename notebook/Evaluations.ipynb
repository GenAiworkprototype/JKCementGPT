{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799ebdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7096e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"What is RAG system?\",\n",
    "    \"What is decision-making loop?\",\n",
    "    \"Explain feedback loop mechanisms.\",\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"A Retrieval-Augmented Generation (RAG) system is a paradigm in Natural Language Processing (NLP) that combines generative and retrieval systems. In its traditional form, it works by retrieving relevant documents or information from external sources (like a database or search engine). This retrieved external knowledge is then used by a generative model to produce responses that are more relevant and contextual.\",\n",
    "    \"In the context of Agentic RAG, a decision-making loop is a context-aware process that decides how to process and use retrieved information. Guided by the system's goals and priorities, these loops evaluate the retrieved data, determine its relevance, and decide on the best response to align with the task's objectives.\",\n",
    "    \"Feedback loop mechanisms are a central feature of Agentic RAG that enable iterative and continuous learning. Unlike traditional systems where the process ends after a response is generated , these loops allow the system to evaluate its generated content against the desired goals. Based on this feedback, the system refines its performance by adjusting both its retrieval and generation processes in real-time.\",\n",
    "]\n",
    "\n",
    "# Dataset\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "csv_path = \"/GenAI Hackathon/2.0/data/qnadata.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4facdae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['094a0be4-024f-48bc-9241-88ded2268bfe',\n",
       "  '0c74f7fd-d97f-4667-bfbc-14d3499f3271',\n",
       "  'ed09d237-a7cc-47e6-b0b4-b25c6d45587a'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"llmoops_dataset\"\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Input and expected output pairs for llmoops_dataset\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73226514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/GenAI Hackathon/2.0\")\n",
    "\n",
    "from pathlib import Path\n",
    "from cementGPT_llm_chat.src.document_ingestion.data_ingestion import ChatIngestor\n",
    "from cementGPT_llm_chat.src.document_chat.retrieval import ConversationalRAG\n",
    "import os\n",
    "\n",
    "# Simple file adapter for local file paths\n",
    "class LocalFileAdapter:\n",
    "    \"\"\"Adapter for local file paths to work with ChatIngestor.\"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = Path(file_path)\n",
    "        self.name = self.path.name\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "\n",
    "\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = \"/GenAI Hackathon/2.0/data/AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the AI Engineering Report using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the AI Engineering Report text file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        \n",
    "        # Create file adapter\n",
    "        file_adapter = LocalFileAdapter(data_path)\n",
    "        \n",
    "        # Build index using ChatIngestor\n",
    "        ingestor = ChatIngestor(\n",
    "            temp_base=\"data\",\n",
    "            faiss_base=\"faiss_index\",\n",
    "            use_session_dirs=True\n",
    "        )\n",
    "        \n",
    "        # Build retriever\n",
    "        ingestor.built_retriver(\n",
    "            uploaded_files=[file_adapter],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get session ID and index path\n",
    "        session_id = ingestor.session_id\n",
    "        index_path = f\"faiss_index/{session_id}\"\n",
    "        \n",
    "        # Create RAG instance and load retriever\n",
    "        rag = ConversationalRAG(session_id=session_id)\n",
    "        rag.load_retriever_from_faiss(\n",
    "            index_path=index_path,\n",
    "            k=k,\n",
    "            index_name=os.getenv(\"FAISS_INDEX_NAME\", \"index\")\n",
    "        )\n",
    "        \n",
    "        # Get answer\n",
    "        answer = rag.invoke(question, chat_history=[])\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95ffef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-10-26T10:39:29.811432Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:39:29.813626Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:39:29.815737Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:39:29.822255Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_160929_2ef8a429\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_160929_2ef8a429\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_160929_2ef8a429\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:39:29.825687Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_160929_2ef8a429\\\\4e937357.pdf\", \"timestamp\": \"2025-10-26T10:39:29.867059Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:39:30.491080Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:39:30.494138Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:39:30.495770Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_160929_2ef8a429\", \"timestamp\": \"2025-10-26T10:39:33.829729Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:39:33.830907Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:39:33.834916Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:39:33.836371Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:39:33.839680Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:39:33.843720Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:39:33.846125Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_160929_2ef8a429\", \"timestamp\": \"2025-10-26T10:39:33.851279Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_160929_2ef8a429\", \"timestamp\": \"2025-10-26T10:39:33.852345Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:39:33.856333Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:39:33.857632Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:39:33.859188Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:39:33.863269Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:39:33.864722Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_160929_2ef8a429\", \"timestamp\": \"2025-10-26T10:39:33.903635Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_160929_2ef8a429\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_160929_2ef8a429\", \"timestamp\": \"2025-10-26T10:39:33.906364Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_160929_2ef8a429\", \"user_input\": \"What is RAG system?\", \"answer_preview\": \"The RAG system uses available external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. It em\", \"timestamp\": \"2025-10-26T10:39:36.423453Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is RAG system?\n",
      "\n",
      "Answer: The RAG system uses available external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. It empowers the system to draw abundant external knowledge with a degree of dynamism, capable of dealing with multiple situations and various complex questions. In its traditional form, relevant documents or pieces of information are retrieved from external sources and then consumed by a generative model to produce contextual responses.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a sample question\n",
    "test_input = {\"question\": \"What is RAG system?\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc9d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0a0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-10-26T10:40:51.340995Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:51.342508Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:40:51.344252Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:40:51.350116Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_161051_2b2e2301\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161051_2b2e2301\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161051_2b2e2301\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:40:51.355189Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161051_2b2e2301\\\\0258344c.pdf\", \"timestamp\": \"2025-10-26T10:40:51.364534Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:40:52.354066Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:40:52.356933Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:40:52.359519Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161051_2b2e2301\", \"timestamp\": \"2025-10-26T10:40:55.627659Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:40:55.629094Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:55.633034Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:55.634416Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:40:55.635590Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:40:55.638915Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:40:55.640894Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_161051_2b2e2301\", \"timestamp\": \"2025-10-26T10:40:55.646335Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161051_2b2e2301\", \"timestamp\": \"2025-10-26T10:40:55.648252Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:55.652054Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:55.653321Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:40:55.654797Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:40:55.661679Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:40:55.663001Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_161051_2b2e2301\", \"timestamp\": \"2025-10-26T10:40:55.710706Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_161051_2b2e2301\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_161051_2b2e2301\", \"timestamp\": \"2025-10-26T10:40:55.712932Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161051_2b2e2301\", \"user_input\": \"What is RAG system?\", \"answer_preview\": \"The RAG system uses available external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. This \", \"timestamp\": \"2025-10-26T10:40:58.501126Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What is RAG system?\n",
      "A1: The RAG system uses available external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. This integration empowers the system to draw abundant external knowledge with a degree of dynamism, capable of dealing with multiple situations and various complex questions. In its traditional form, relevant documents or pieces of information are retrieved from external sources and then consumed by a generative model to produce contextual responses.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-10-26T10:40:58.512313Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:40:58.513579Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:40:58.514799Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:40:58.520334Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_161058_ae650ef7\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161058_ae650ef7\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161058_ae650ef7\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:40:58.526468Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161058_ae650ef7\\\\0d1cc6bc.pdf\", \"timestamp\": \"2025-10-26T10:40:58.532944Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:40:59.100668Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:40:59.105084Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:40:59.108226Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161058_ae650ef7\", \"timestamp\": \"2025-10-26T10:41:02.420980Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:41:02.423416Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:02.427304Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:02.428732Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:41:02.429689Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:41:02.433162Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:41:02.434980Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_161058_ae650ef7\", \"timestamp\": \"2025-10-26T10:41:02.442243Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161058_ae650ef7\", \"timestamp\": \"2025-10-26T10:41:02.444170Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:02.447016Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:02.448978Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:41:02.450677Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:41:02.455212Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:41:02.459059Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_161058_ae650ef7\", \"timestamp\": \"2025-10-26T10:41:02.503845Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_161058_ae650ef7\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_161058_ae650ef7\", \"timestamp\": \"2025-10-26T10:41:02.506665Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161058_ae650ef7\", \"user_input\": \"What is decision-making loop?\", \"answer_preview\": \"Agentic RAG uses context-aware decision-making loops to decide how to process and use retrieved information, which are guided by the system's goals an\", \"timestamp\": \"2025-10-26T10:41:05.035758Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: What is decision-making loop?\n",
      "A2: Agentic RAG uses context-aware decision-making loops to decide how to process and use retrieved information, which are guided by the system's goals and priorities. The system evaluates harvested data, determines its relevance, and makes decisions to create the best responses that are consistent with the stated mission. The system continues to refine its decision making and make further decisions from the feedback of previous actions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-10-26T10:41:05.045771Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:05.047032Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:41:05.047892Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:41:05.052354Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_161105_d3c86576\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161105_d3c86576\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161105_d3c86576\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:41:05.058069Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_161105_d3c86576\\\\d2ebcbd1.pdf\", \"timestamp\": \"2025-10-26T10:41:05.065640Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:41:05.579503Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:41:05.583878Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:41:05.585870Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_161105_d3c86576\", \"timestamp\": \"2025-10-26T10:41:08.635706Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:41:08.638222Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:08.642179Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:08.643900Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:41:08.645303Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:41:08.648570Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:41:08.649825Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_161105_d3c86576\", \"timestamp\": \"2025-10-26T10:41:08.656162Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161105_d3c86576\", \"timestamp\": \"2025-10-26T10:41:08.658130Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:08.662745Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:41:08.664490Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:41:08.665886Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:41:08.669189Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:41:08.673051Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_161105_d3c86576\", \"timestamp\": \"2025-10-26T10:41:08.718201Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_161105_d3c86576\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_161105_d3c86576\", \"timestamp\": \"2025-10-26T10:41:08.719826Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_161105_d3c86576\", \"user_input\": \"Explain feedback loop mechanisms.\", \"answer_preview\": \"Agentic RAG contains feedback loop mechanisms that enable the system to evaluate retrieved and generated content with respect to desired goals and out\", \"timestamp\": \"2025-10-26T10:41:11.419369Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: Explain feedback loop mechanisms.\n",
      "A3: Agentic RAG contains feedback loop mechanisms that enable the system to evaluate retrieved and generated content with respect to desired goals and outcomes. The system's performance is refined simultaneously on the retrieval and generation processes based on this feedback. This iterative learning model allows the system to evolve with every interaction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Test with all golden questions\n",
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(inputs, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b387a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-llmoops_dataset-qa-rag-ae551b4f' at:\n",
      "https://smith.langchain.com/o/2df5139e-03a9-47c7-8f97-fe54947713a4/datasets/517197ea-52e0-44a3-8e3b-131a2e1c400e/compare?selectedSessions=5ff0007d-6f0d-43a0-96ad-cbdb8e3d8fd7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GenAI Hackathon\\2.0\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "0it [00:00, ?it/s]{\"timestamp\": \"2025-10-26T10:50:31.147192Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:31.150165Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:31.152882Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:31.164731Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_162031_7de5525b\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162031_7de5525b\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162031_7de5525b\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:50:31.171677Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162031_7de5525b\\\\a8f927a5.pdf\", \"timestamp\": \"2025-10-26T10:50:31.180831Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:50:32.023226Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:50:32.028074Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:32.030475Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162031_7de5525b\", \"timestamp\": \"2025-10-26T10:50:35.224161Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:50:35.225847Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:35.230919Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:35.233002Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:35.235069Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:35.242390Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:50:35.244544Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_162031_7de5525b\", \"timestamp\": \"2025-10-26T10:50:35.251550Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162031_7de5525b\", \"timestamp\": \"2025-10-26T10:50:35.254501Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:35.260846Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:35.263569Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:35.265869Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:35.272549Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:35.277188Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_162031_7de5525b\", \"timestamp\": \"2025-10-26T10:50:35.347458Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_162031_7de5525b\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_162031_7de5525b\", \"timestamp\": \"2025-10-26T10:50:35.349786Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162031_7de5525b\", \"user_input\": \"What is RAG system?\", \"answer_preview\": \"The RAG system uses external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. This integratio\", \"timestamp\": \"2025-10-26T10:50:38.088172Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "1it [00:08,  8.83s/it]{\"timestamp\": \"2025-10-26T10:50:39.974120Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:39.975370Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:39.976413Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:39.979812Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_162039_e956e75d\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162039_e956e75d\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162039_e956e75d\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:50:39.982755Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162039_e956e75d\\\\6644ca53.pdf\", \"timestamp\": \"2025-10-26T10:50:39.993618Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:50:40.732196Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:50:40.735811Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:40.737856Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162039_e956e75d\", \"timestamp\": \"2025-10-26T10:50:43.875483Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:50:43.877506Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:43.881679Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:43.883589Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:43.887221Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:43.892401Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:50:43.894650Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_162039_e956e75d\", \"timestamp\": \"2025-10-26T10:50:43.898742Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162039_e956e75d\", \"timestamp\": \"2025-10-26T10:50:43.900395Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:43.907037Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:43.910929Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:43.912519Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:43.916510Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:43.918611Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_162039_e956e75d\", \"timestamp\": \"2025-10-26T10:50:43.960695Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_162039_e956e75d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_162039_e956e75d\", \"timestamp\": \"2025-10-26T10:50:43.962071Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162039_e956e75d\", \"user_input\": \"What is decision-making loop?\", \"answer_preview\": \"Agentic RAG uses a context-aware decision-making loop to decide how to process and use retrieved information. These loops are guided by the system's g\", \"timestamp\": \"2025-10-26T10:50:46.525042Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "2it [00:16,  8.20s/it]{\"timestamp\": \"2025-10-26T10:50:47.729139Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:47.730466Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:47.731788Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:47.735662Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_162047_e6e5971b\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162047_e6e5971b\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162047_e6e5971b\", \"sessionized\": true, \"timestamp\": \"2025-10-26T10:50:47.739286Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_162047_e6e5971b\\\\dae853ae.pdf\", \"timestamp\": \"2025-10-26T10:50:47.743918Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T10:50:48.258471Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T10:50:48.264278Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:48.266902Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_162047_e6e5971b\", \"timestamp\": \"2025-10-26T10:50:51.329244Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T10:50:51.330624Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:51.334263Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:51.335654Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:51.336687Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:51.339950Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T10:50:51.341116Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_162047_e6e5971b\", \"timestamp\": \"2025-10-26T10:50:51.345980Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162047_e6e5971b\", \"timestamp\": \"2025-10-26T10:50:51.348494Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:51.352782Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T10:50:51.354511Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T10:50:51.357487Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T10:50:51.363451Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T10:50:51.365001Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_162047_e6e5971b\", \"timestamp\": \"2025-10-26T10:50:51.403036Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_162047_e6e5971b\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_162047_e6e5971b\", \"timestamp\": \"2025-10-26T10:50:51.404210Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_162047_e6e5971b\", \"user_input\": \"Explain feedback loop mechanisms.\", \"answer_preview\": \"Agentic RAG contains feedback loop mechanisms that enable the system to evaluate retrieved and generated content with respect to desired goals and out\", \"timestamp\": \"2025-10-26T10:50:53.920327Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "3it [00:25,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# create a Google LLM instance for evaluation\n",
    "eval_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",                 # pick a model you know works for chat\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=512,\n",
    ")\n",
    "\n",
    "# pass the llm instance via the evaluator config\n",
    "qa_evaluator = [\n",
    "    LangChainStringEvaluator(\n",
    "        \"cot_qa\",\n",
    "        config={\"llm\": eval_llm}   # this tells the evaluator to use your Google LLM\n",
    "    )\n",
    "]\n",
    "\n",
    "# now run evaluation (same as before)\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=\"llmoops_dataset\",\n",
    "    evaluators=qa_evaluator,\n",
    "    experiment_prefix=\"test-llmoops_dataset-qa-rag\",\n",
    "    metadata={\"variant\": \"Agentic RAG ...\", \"chunk_size\": 1000, \"chunk_overlap\": 200, \"k\": 5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9e2bd",
   "metadata": {},
   "source": [
    "### Custom Correctness Evaluator\n",
    "Creating an LLM-as-a-Judge evaluator to assess semantic and factual alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c9d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def correctness_evaluator(run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Custom LLM-as-a-Judge evaluator for correctness.\n",
    "    \n",
    "    Correctness means how well the actual model output matches the reference output \n",
    "    in terms of factual accuracy, coverage, and meaning.\n",
    "    \n",
    "    Args:\n",
    "        run: The Run object containing the actual outputs\n",
    "        example: The Example object containing the expected outputs\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'score' (1 for correct, 0 for incorrect) and 'reasoning'\n",
    "    \"\"\"\n",
    "    # Extract actual and expected outputs\n",
    "    actual_output = run.outputs.get(\"answer\", \"\")\n",
    "    expected_output = example.outputs.get(\"answer\", \"\")\n",
    "    input_question = example.inputs.get(\"question\", \"\")\n",
    "    \n",
    "    # Define the evaluation prompt\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an evaluator whose job is to judge correctness.\n",
    "\n",
    "Correctness means how well the actual model output matches the reference output in terms of factual accuracy, coverage, and meaning.\n",
    "\n",
    "- If the actual output matches the reference output semantically (even if wording differs), it should be marked correct.\n",
    "- If the output misses key facts, introduces contradictions, or is factually incorrect, it should be marked incorrect.\n",
    "\n",
    "Do not penalize for stylistic or formatting differences unless they change meaning.\"\"\"),\n",
    "        (\"human\", \"\"\"<example>\n",
    "<input>\n",
    "{input}\n",
    "</input>\n",
    "\n",
    "<output>\n",
    "Expected Output: {expected_output}\n",
    "\n",
    "Actual Output: {actual_output}\n",
    "</output>\n",
    "</example>\n",
    "\n",
    "Please grade the following agent run given the input, expected output, and actual output.\n",
    "Focus only on correctness (semantic and factual alignment).\n",
    "\n",
    "Respond with:\n",
    "1. A brief reasoning (1-2 sentences)\n",
    "2. A final verdict: either \"CORRECT\" or \"INCORRECT\"\n",
    "\n",
    "Format your response as:\n",
    "Reasoning: [your reasoning]\n",
    "Verdict: [CORRECT or INCORRECT]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Initialize LLM (using Gemini as shown in your config)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Create chain and invoke\n",
    "    chain = eval_prompt | llm\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\n",
    "            \"input\": input_question,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"actual_output\": actual_output\n",
    "        })\n",
    "        \n",
    "        response_text = response.content\n",
    "        \n",
    "        # Parse the response\n",
    "        reasoning = \"\"\n",
    "        verdict = \"\"\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"Reasoning:\"):\n",
    "                reasoning = line.replace(\"Reasoning:\", \"\").strip()\n",
    "            elif line.startswith(\"Verdict:\"):\n",
    "                verdict = line.replace(\"Verdict:\", \"\").strip()\n",
    "        \n",
    "        # Convert verdict to score (1 for correct, 0 for incorrect)\n",
    "        score = 1 if \"CORRECT\" in verdict.upper() else 0\n",
    "        \n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": score,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"comment\": f\"Verdict: {verdict}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": 0,\n",
    "            \"reasoning\": f\"Error during evaluation: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da0f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'llmoops-correctness-eval-f63d32fe' at:\n",
      "https://smith.langchain.com/o/2df5139e-03a9-47c7-8f97-fe54947713a4/datasets/517197ea-52e0-44a3-8e3b-131a2e1c400e/compare?selectedSessions=63488257-b575-422f-b259-0dfcdc8d7805\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2025-10-26T11:58:44.787285Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:58:44.789251Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:58:44.791330Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:58:44.798045Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_172844_c1b03e06\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172844_c1b03e06\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172844_c1b03e06\", \"sessionized\": true, \"timestamp\": \"2025-10-26T11:58:44.803158Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172844_c1b03e06\\\\146580f9.pdf\", \"timestamp\": \"2025-10-26T11:58:44.809723Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T11:58:45.358925Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T11:58:45.362332Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:58:45.364096Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172844_c1b03e06\", \"timestamp\": \"2025-10-26T11:58:48.560187Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T11:58:48.561711Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T11:58:48.565040Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:58:48.566320Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:58:48.567594Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:58:48.570760Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T11:58:48.572089Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_172844_c1b03e06\", \"timestamp\": \"2025-10-26T11:58:48.578504Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172844_c1b03e06\", \"timestamp\": \"2025-10-26T11:58:48.580146Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T11:58:48.583690Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:58:48.585253Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:58:48.586821Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:58:48.593946Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:58:48.596115Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_172844_c1b03e06\", \"timestamp\": \"2025-10-26T11:58:48.648727Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_172844_c1b03e06\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_172844_c1b03e06\", \"timestamp\": \"2025-10-26T11:58:48.649986Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172844_c1b03e06\", \"user_input\": \"What is RAG system?\", \"answer_preview\": \"The RAG system uses available external knowledge from a retrieval component as an extension to the raw knowledge passed to the generative model. It em\", \"timestamp\": \"2025-10-26T11:58:51.224525Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "1it [00:15, 15.79s/it]{\"timestamp\": \"2025-10-26T11:59:00.577094Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:00.578468Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:00.579791Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:00.583151Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_172900_a7e8ab98\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172900_a7e8ab98\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172900_a7e8ab98\", \"sessionized\": true, \"timestamp\": \"2025-10-26T11:59:00.586506Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172900_a7e8ab98\\\\1282c0f4.pdf\", \"timestamp\": \"2025-10-26T11:59:00.596932Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T11:59:01.103008Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T11:59:01.107763Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:59:01.110785Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172900_a7e8ab98\", \"timestamp\": \"2025-10-26T11:59:04.178600Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T11:59:04.180432Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:04.184030Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:04.185460Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:04.186863Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:04.191075Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T11:59:04.192328Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_172900_a7e8ab98\", \"timestamp\": \"2025-10-26T11:59:04.197024Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172900_a7e8ab98\", \"timestamp\": \"2025-10-26T11:59:04.198700Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:04.202777Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:04.206839Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:04.209312Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:04.213504Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:59:04.214876Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_172900_a7e8ab98\", \"timestamp\": \"2025-10-26T11:59:04.252923Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_172900_a7e8ab98\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_172900_a7e8ab98\", \"timestamp\": \"2025-10-26T11:59:04.256384Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172900_a7e8ab98\", \"user_input\": \"What is decision-making loop?\", \"answer_preview\": \"Agentic RAG uses context-aware decision-making loops to decide how to process and use retrieved information. These loops are guided by the system's go\", \"timestamp\": \"2025-10-26T11:59:06.698895Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "2it [00:30, 14.88s/it]{\"timestamp\": \"2025-10-26T11:59:14.815865Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:14.817133Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:14.818614Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:14.822490Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251026_172914_912d24f4\", \"temp_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172914_912d24f4\", \"faiss_dir\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172914_912d24f4\", \"sessionized\": true, \"timestamp\": \"2025-10-26T11:59:14.826022Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence.pdf\", \"saved_as\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\data\\\\session_20251026_172914_912d24f4\\\\ffd2dc1f.pdf\", \"timestamp\": \"2025-10-26T11:59:14.830618Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 10, \"timestamp\": \"2025-10-26T11:59:15.322538Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 39, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-10-26T11:59:15.324927Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:59:15.326710Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"C:\\\\GenAI Hackathon\\\\2.0\\\\notebook\\\\faiss_index\\\\session_20251026_172914_912d24f4\", \"timestamp\": \"2025-10-26T11:59:18.410244Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-10-26T11:59:18.412176Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:18.415568Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:18.417019Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:18.418895Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:18.422780Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2025-10-26T11:59:18.424349Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251026_172914_912d24f4\", \"timestamp\": \"2025-10-26T11:59:18.429567Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172914_912d24f4\", \"timestamp\": \"2025-10-26T11:59:18.431561Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:18.437175Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-10-26T11:59:18.439931Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-10-26T11:59:18.442063Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2025-10-26T11:59:18.447420Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"gemini-embedding-001\", \"timestamp\": \"2025-10-26T11:59:18.448674Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251026_172914_912d24f4\", \"timestamp\": \"2025-10-26T11:59:18.489722Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251026_172914_912d24f4\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251026_172914_912d24f4\", \"timestamp\": \"2025-10-26T11:59:18.491191Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251026_172914_912d24f4\", \"user_input\": \"Explain feedback loop mechanisms.\", \"answer_preview\": \"Agentic RAG contains feedback loop mechanisms that enable the system to evaluate retrieved and generated content with respect to desired goals and out\", \"timestamp\": \"2025-10-26T11:59:21.063449Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "3it [00:47, 15.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed! Check the LangSmith UI for detailed results.\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with the custom correctness evaluator\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Define evaluators - using custom correctness evaluator\n",
    "evaluators = [correctness_evaluator]\n",
    "\n",
    "dataset_name = \"llmoops_dataset\"\n",
    "\n",
    "# Run evaluation\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=\"llmoops-correctness-eval\",\n",
    "    description=\"Evaluating RAG system with custom correctness evaluator (LLM-as-a-Judge)\",\n",
    "    metadata={\n",
    "        \"variant\": \"AgenticRAGRedefiningRetrieval-AugmentedGenerationforAdaptiveIntelligence\",\n",
    "        \"evaluator\": \"custom_correctness_llm_judge\",\n",
    "        \"model\": \"gemini-2.5-pro\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation completed! Check the LangSmith UI for detailed results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826a795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2-0 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
